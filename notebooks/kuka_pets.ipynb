{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(\n",
    "    inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "os.sys.path.insert(1, parentdir+'/src')\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pybullet as p\n",
    "import stage.envs\n",
    "from stage.tasks.kuka.reaching import KukaReaching\n",
    "from stage.utils.nn import use_gpu\n",
    "use_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'serif',\n",
    "        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "np.set_printoptions(precision=3, linewidth=200, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = parentdir + '/data/kuka/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train = np.load(savepath+'data_pd_reg.npy')\n",
    "# task = KukaReaching(render=True)\n",
    "# task.visualize_training_data(data_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = KukaReaching(render=False)\n",
    "\n",
    "# Read task parameters, should we use a separate class to wrap this?\n",
    "\n",
    "nq, nv, nu, nx = task.nq, task.nv, task.nu, task.nx\n",
    "dt_control, dt_env = task.dt_control, task.dt_env\n",
    "q_lb, q_ub = task.q_lb, task.q_ub\n",
    "v_lb, v_ub = -100 * torch.ones_like(q_lb), 100 * torch.ones_like(q_ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup action parameterization\n",
    "\n",
    "from stage.controllers.actor import Actor\n",
    "from stage.controllers.pd import PD\n",
    "\n",
    "na = 14\n",
    "gain_ub = torch.Tensor([30, 15, 30, 30, 5, 3, 0.1])\n",
    "gain_lb = 0. * torch.ones((nq))\n",
    "action_ub = torch.cat((gain_ub, q_ub))\n",
    "action_lb = torch.cat((gain_lb, q_lb))\n",
    "actor = Actor(PD(nx, nq, nv, nu), action_lb, action_ub)\n",
    "\n",
    "task.cost.actor = actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model learning\n",
    "\n",
    "from stage.dynamics.probabilistic_ensemble import ProbabilisticEnsemble, DefaultDx\n",
    "\n",
    "ensemble_size = 5 \n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "dynamics = ProbabilisticEnsemble(nx, nq, nv, na, dt_control, \n",
    "                                 DefaultDx,\n",
    "                                 ensemble_size, \n",
    "                                 learning_rate=0.001)\n",
    "\n",
    "dynamics.state_lb = torch.cat((q_lb, v_lb))\n",
    "dynamics.state_ub = torch.cat((q_ub, v_ub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup controller\n",
    "\n",
    "from stage.controllers.pets import PETS\n",
    "\n",
    "plan_horizon = 50\n",
    "n_particles = 20\n",
    "pop_size = 500\n",
    "assert n_particles % ensemble_size == 0\n",
    "\n",
    "controller = PETS(dynamics, task.cost, actor,\n",
    "                  plan_horizon, n_particles, pop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup learner\n",
    "from stage.learners.learn_and_control_model import LearnAndControlModel\n",
    "learner = LearnAndControlModel(task, dynamics, controller, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4006, -0.5008, -0.0008]])\n",
      "tensor([[0.3931, 0.4873, 0.0099]])\n"
     ]
    }
   ],
   "source": [
    "q_start = torch.Tensor(task.q_start).unsqueeze(0)\n",
    "q_desired = task.cost.desired[:nq].unsqueeze(0)\n",
    "\n",
    "print (task.cost.fwk(q_start, 6)[:, :3, 3])\n",
    "print (task.cost.fwk(q_desired, 6)[:, :3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network training: 100%|██████████| 10/10 [00:00<00:00, 31.03epoch(s)/s, Training loss MSE=0.36754477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Initial state:  tensor([-7.5276e-01,  1.4371e+00, -2.0407e-01, -1.1921e+00, -6.2286e-03,\n",
      "         2.1652e-01,  6.4782e-05, -5.8945e-04,  2.4817e-02,  1.3766e-03,\n",
      "         1.9955e-02,  2.1779e-02, -8.2250e-03,  3.1124e-02])\n",
      "avg. decision time:  0.023402458826700848\n",
      "obs. reward:  -109.49114\n",
      "act. reward:  -1.9866807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network training: 100%|██████████| 10/10 [00:00<00:00, 20.49epoch(s)/s, Training loss MSE=0.16929023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n",
      "Initial state:  tensor([-7.5276e-01,  1.4371e+00, -2.0407e-01, -1.1921e+00, -6.2286e-03,\n",
      "         2.1652e-01,  6.4782e-05, -5.8945e-04,  2.4817e-02,  1.3766e-03,\n",
      "         1.9955e-02,  2.1779e-02, -8.2250e-03,  3.1124e-02])\n",
      "avg. decision time:  0.779207615852356\n",
      "obs. reward:  -92.16981\n",
      "act. reward:  -0.9474853\n"
     ]
    }
   ],
   "source": [
    "lip_reg = False\n",
    "\n",
    "if lip_reg:\n",
    "    controller.regularize(1)\n",
    "    file_name = savepath + 'data_pd_reg'\n",
    "else: \n",
    "    controller.regularize(0)\n",
    "    file_name = savepath + 'data_pd_noreg'\n",
    "    \n",
    "_ = learner.learn(50, verbose=True)\n",
    "learner.save_training_data(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj, log = task.perform(task.goal, controller)\n",
    "act_seq = traj[:, nx:nx+na]\n",
    "initial_obs = traj[0, :nx]\n",
    "final_obs = traj[-1, :nx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 50\n",
    "traj_pred = dynamics.unroll(initial_obs, \n",
    "                            act_seq, \n",
    "                            n_sample)\n",
    "\n",
    "predicted_err = torch.norm(traj_pred[-1, :, :]-final_obs.expand(n_sample, -1), p=2, dim=1)\n",
    "print (predicted_err.mean())\n",
    "print (predicted_err.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_horizon = task.task_horizon\n",
    "ee_pred = torch.zeros(task_horizon, n_sample, 3)\n",
    "ee = torch.zeros(task_horizon, 3)\n",
    "\n",
    "for n in range(task_horizon):\n",
    "    ee_pred[n] = task.cost.fwk(traj_pred[n,:,:nq], 6)[:, :3, 3]\n",
    "    ee[n] = task.cost.fwk(traj[n:n+1,:nq], 6)[:, :3, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee_pred_mean = torch.mean(ee_pred, dim=1)\n",
    "ee_pred_std = torch.std(ee_pred, dim=1)\n",
    "\n",
    "ee_pred_mean_np = ee_pred_mean.detach().cpu().numpy()\n",
    "ee_pred_std_np = ee_pred_std.detach().cpu().numpy()\n",
    "ee_np = ee.detach().cpu().numpy()\n",
    "\n",
    "goal = task.cost.goal.repeat(task_horizon, 1)\n",
    "goal = goal.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ee_np[:,0],ee_np[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 3\n",
    "dt = dt_control\n",
    "fig, ax = plt.subplots(d, figsize=(10, d * 6))\n",
    "t = np.arange(0.0, task_horizon*dt, dt)\n",
    "dlb = ee_pred_mean_np - ee_pred_std_np\n",
    "ub = ee_pred_mean_np + ee_pred_std_np\n",
    "\n",
    "for i in range(d):\n",
    "    ax[i].plot(t, ee_np[:, i], lw=4, color='orange', label='actual')\n",
    "    ax[i].plot(t, ee_pred_mean_np[:, i], lw=4, color='b', label='predicted mean')\n",
    "    ax[i].plot(t, goal[:, i], lw=2, color='k', ls='-.', label='goal')\n",
    "    lb = ee_pred_mean_np - ee_pred_std_np\n",
    "    ub = ee_pred_mean_np + ee_pred_std_np\n",
    "    ax[i].fill_between(t, lb[:, i], ub[:, i], facecolor='blue',\n",
    "                alpha=0.2)\n",
    "    _ = ax[i].grid()\n",
    "#     _ = ax[i].set_ylim([-3.2, 3.2])\n",
    "#     ax[i].legend(loc='upper center', bbox_to_anchor=(0.5, 1.3),\n",
    "#              ncol=3, fancybox=True, shadow=True)\n",
    "# fig.savefig('prediction_with_reg_150steps' + '.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# traj_pred_mean = torch.mean(traj_pred, dim=1)\n",
    "# traj_pred_std = torch.std(traj_pred, dim=1)\n",
    "\n",
    "# traj_pred_mean_np = traj_pred_mean.detach().cpu().numpy()\n",
    "# traj_pred_std_np = traj_pred_std.detach().cpu().numpy()\n",
    "# traj_np = traj.detach().cpu().numpy()\n",
    "\n",
    "# desired = task.cost.desired.repeat((task_horizon, 1))\n",
    "# desired = desired.detach().cpu().numpy()\n",
    "\n",
    "# d = nq\n",
    "# dt = dt_control\n",
    "# fig, ax = plt.subplots(d, figsize=(10, d * 6))\n",
    "# t = np.arange(0.0, task_horizon*dt, dt)\n",
    "# dlb = traj_pred_mean_np - traj_pred_std_np\n",
    "# ub = traj_pred_mean_np + traj_pred_std_np\n",
    "\n",
    "# for i in range(d):\n",
    "#     ax[i].plot(t, traj_np[:, i], lw=4, color='orange', label='actual')\n",
    "#     ax[i].plot(t, traj_pred_mean_np[:, i], lw=4, color='b', label='predicted mean')\n",
    "#     ax[i].plot(t, desired[:, i], lw=2, color='k', ls='-.', label='desired')\n",
    "#     lb = traj_pred_mean_np - traj_pred_std_np\n",
    "#     ub = traj_pred_mean_np + traj_pred_std_np\n",
    "#     ax[i].fill_between(t, lb[:, i], ub[:, i], facecolor='blue',\n",
    "#                 alpha=0.2)\n",
    "#     _ = ax[i].grid()\n",
    "# #     _ = ax[i].set_ylim([-3.2, 3.2])\n",
    "# #     ax[i].legend(loc='upper center', bbox_to_anchor=(0.5, 1.3),\n",
    "# #              ncol=3, fancybox=True, shadow=True)\n",
    "# # fig.savefig('prediction_with_reg_150steps' + '.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
