{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(\n",
    "    inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "os.sys.path.insert(1, parentdir+'/src')\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import trange\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import pybullet as p\n",
    "import stage.envs\n",
    "from stage.tasks.twolink.reaching import TwoLinkReaching\n",
    "from stage.utils.nn import use_gpu\n",
    "use_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = parentdir + '/data/twolink/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stage.utils.nn import bquad, bmv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = TwoLinkReaching(render=False)\n",
    "\n",
    "# Read task parameters, should we use a separate class to wrap this?\n",
    "\n",
    "nq, nv, nu, nx = task.nq, task.nv, task.nu, task.nx\n",
    "dt_control, dt_env = task.dt_control, task.dt_env\n",
    "q_lb, q_ub = task.q_lb, task.q_ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup action parameterization\n",
    "\n",
    "from stage.controllers.actor import Actor\n",
    "from stage.controllers.trivial import Identity\n",
    "from stage.controllers.pd import PD\n",
    "\n",
    "# na = 2\n",
    "# action_ub = torch.Tensor(task.env.action_space.high)\n",
    "# action_lb = torch.Tensor(task.env.action_space.low)\n",
    "\n",
    "# actor = Actor(na, Identity(nq, nv, nu), action_lb, action_ub)\n",
    "\n",
    "na = 4\n",
    "gain_ub = 50 * torch.ones((nq))\n",
    "gain_lb = 0. * torch.ones((nq))\n",
    "\n",
    "action_ub = torch.cat((gain_ub, q_ub))\n",
    "action_lb = torch.cat((gain_lb, q_lb))\n",
    "\n",
    "actor = Actor(na, PD(nq, nv, nu), action_lb, action_ub)\n",
    "\n",
    "# this is extremely ugly\n",
    "task.cost.actor = actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model learning\n",
    "\n",
    "from stage.dynamics.mlp import MLPDyn, DefaultDx\n",
    "dynamics = MLPDyn(nx, nq, nv, na, dt_control, DefaultDx)\n",
    "\n",
    "# from stage.dynamics.probabilistic_ensemble import ProbabilisticEnsemble, DefaultDx\n",
    "# ensemble_size = 5\n",
    "# dynamics = ProbabilisticEnsemble(nq, nv, na, dt_control, \n",
    "#                                  DefaultDx,\n",
    "#                                  ensemble_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup controller\n",
    "from stage.controllers.trivial import RandomController\n",
    "\n",
    "controller = RandomController(nx, actor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup learner\n",
    "\n",
    "from stage.learners.learn_and_control_model import LearnAndControlModel\n",
    "learner = LearnAndControlModel(task, dynamics, controller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network training: 100%|██████████| 10/10 [00:00<00:00, 21.13epoch(s)/s, Training loss MSE=3.2290807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "avg. decision time:  0.004556918144226074\n",
      "obs. reward:  -225.79874\n",
      "act. reward:  -1.3134795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network training: 100%|██████████| 10/10 [00:01<00:00,  9.97epoch(s)/s, Training loss MSE=0.74436444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n",
      "avg. decision time:  0.004950554370880127\n",
      "obs. reward:  -251.74245\n",
      "act. reward:  -1.044556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network training: 100%|██████████| 10/10 [00:00<00:00, 15.45epoch(s)/s, Training loss MSE=0.7164073]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2\n",
      "avg. decision time:  0.004574401378631592\n",
      "obs. reward:  -254.93073\n",
      "act. reward:  -1.3032212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network training: 100%|██████████| 10/10 [00:02<00:00,  4.13epoch(s)/s, Training loss MSE=0.85856086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  3\n",
      "avg. decision time:  0.004606177806854248\n",
      "obs. reward:  -238.76358\n",
      "act. reward:  -1.6558219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network training: 100%|██████████| 10/10 [00:03<00:00,  3.02epoch(s)/s, Training loss MSE=0.7623656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  4\n",
      "avg. decision time:  0.0047782516479492184\n",
      "obs. reward:  -199.31319\n",
      "act. reward:  -1.3376784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network training: 100%|██████████| 10/10 [00:03<00:00,  2.53epoch(s)/s, Training loss MSE=0.80403566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  5\n",
      "avg. decision time:  0.0047642230987548825\n",
      "obs. reward:  -288.58432\n",
      "act. reward:  -1.1214055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network training: 100%|██████████| 10/10 [00:04<00:00,  2.20epoch(s)/s, Training loss MSE=0.8618373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  6\n",
      "avg. decision time:  0.004790108203887939\n",
      "obs. reward:  -355.65512\n",
      "act. reward:  -1.1104771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network training: 100%|██████████| 10/10 [00:05<00:00,  1.94epoch(s)/s, Training loss MSE=0.7527232]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  7\n",
      "avg. decision time:  0.0048086953163146975\n",
      "obs. reward:  -342.1955\n",
      "act. reward:  -1.0180559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network training: 100%|██████████| 10/10 [00:05<00:00,  1.68epoch(s)/s, Training loss MSE=0.65684843]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  8\n",
      "avg. decision time:  0.004764320850372314\n",
      "obs. reward:  -308.07324\n",
      "act. reward:  -1.4148028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network training: 100%|██████████| 10/10 [00:06<00:00,  1.50epoch(s)/s, Training loss MSE=0.7045032]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  9\n",
      "avg. decision time:  0.004783873558044434\n",
      "obs. reward:  -324.61295\n",
      "act. reward:  -1.0117773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_ = learner.learn(10, verbose=True)\n",
    "learner.save_training_data(savepath+'data_pd_reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg. decision time:  0.004664881229400635\n",
      "obs. reward:  -187.37099\n",
      "act. reward:  -1.6212811\n"
     ]
    }
   ],
   "source": [
    "traj, log = task.perform(task.goal, controller)\n",
    "act_seq = traj[:, nx:nx+na]\n",
    "initial_obs = traj[0, :nx]\n",
    "final_obs = traj[-1, :nx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6076, grad_fn=<MeanBackward0>)\n",
      "tensor(2.6337, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "n_sample = 50\n",
    "traj_pred = dynamics.unroll(initial_obs, \n",
    "                            act_seq, \n",
    "                            n_sample)\n",
    "\n",
    "predicted_err = torch.norm(traj_pred[-1, :, :]-final_obs.expand(n_sample, -1), p=2, dim=1)\n",
    "print (predicted_err.mean())\n",
    "print (predicted_err.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stage.utils.nn import jacobian_vector_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = initial_obs.clone()\n",
    "a = act_seq[0].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = task.cost.l(x, a, diff=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-607ffabbf5a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0milqr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mILQR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdynamics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_horizon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0milqr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ws/stage/src/stage/controllers/ilqr.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, x, actions_init, horizon, max_it, on_iteration)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m# line search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                     \u001b[0mrollout_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m                     \u001b[0mJ_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollout_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ws/stage/src/stage/controllers/ilqr.py\u001b[0m in \u001b[0;36mcontrol\u001b[0;34m(self, rollout, sols, alpha)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mx_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0ma_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma_\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from stage.controllers.ilqr import ILQR\n",
    "\n",
    "ilqr = ILQR(dynamics, task.cost, actor, task.task_horizon)\n",
    "sols = ilqr.optimize(initial_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_horizon = task.task_horizon\n",
    "\n",
    "traj_pred_mean = torch.mean(traj_pred, dim=1)\n",
    "traj_pred_std = torch.std(traj_pred, dim=1)\n",
    "traj_pred_mean = traj_pred_mean.detach().cpu().numpy()\n",
    "traj_pred_std = traj_pred_std.detach().cpu().numpy()\n",
    "traj = traj.detach().cpu().numpy()\n",
    "\n",
    "desired = task.cost.desired.repeat((task_horizon, 1))\n",
    "desired = desired.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'serif',\n",
    "        'size'   : 22}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "np.set_printoptions(precision=3, linewidth=200, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traj_pred_mean = np.load('traj_pred_mean.npy')\n",
    "# traj_pred_std = np.load('traj_pred_std.npy')\n",
    "# traj = np.load('traj.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = nq\n",
    "dt = dt_control\n",
    "fig, ax = plt.subplots(d, figsize=(10, d * 6))\n",
    "t = np.arange(0.0, task_horizon*dt, dt)\n",
    "lb = traj_pred_mean - traj_pred_std\n",
    "ub = traj_pred_mean + traj_pred_std\n",
    "\n",
    "for i in range(d):\n",
    "    ax[i].plot(t, traj[:, i], lw=4, color='orange', label='actual')\n",
    "    ax[i].plot(t, traj_pred_mean[:, i], lw=4, color='b', label='predicted mean')\n",
    "#     ax[i].plot(t, desired[:, i], lw=2, color='k', ls='-.', label='desired')\n",
    "    lb = traj_pred_mean - traj_pred_std\n",
    "    ub = traj_pred_mean + traj_pred_std\n",
    "    ax[i].fill_between(t, lb[:, i], ub[:, i], facecolor='blue',\n",
    "                alpha=0.2)\n",
    "    _ = ax[i].grid()\n",
    "    _ = ax[i].set_ylim([-3.2, 3.2])\n",
    "    ax[i].legend(loc='upper center', bbox_to_anchor=(0.5, 1.3),\n",
    "             ncol=3, fancybox=True, shadow=True)\n",
    "# fig.savefig('prediction_with_reg_150steps' + '.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
